conf-path: conf/chipster.yaml

# Service accounts
# all config items starting with "service-password-" will be automatically authenticated as Role.SERVER 

service-password-auth: auth
service-password-session-db: session-db
service-password-service-locator: service-locator
service-password-scheduler: scheduler
service-password-comp: comp
service-password-file-broker: file-broker
service-password-session-worker: session-worker
service-password-web-server: web-server
service-password-toolbox: toolbox
service-password-job-history: job-history
service-password-backup: backup
service-password-file-storage: file-storage
service-password-type-service: type-service

# Admin accounts
# all config items starting with "admin-username-" (username in the value) will be automatically authenticated as Role.ADMIN
admin-username-1: admin

   
# Internal and external service addresses

url-int-web-server: http://{{public-ip}}:8000
url-ext-web-server: http://{{public-ip}}:8000
url-int-auth: http://{{public-ip}}:8002
url-ext-auth: http://{{public-ip}}:8002
url-int-service-locator: http://{{public-ip}}:8003
url-ext-service-locator: http://{{public-ip}}:8003 
url-int-session-db: http://{{public-ip}}:8004
url-ext-session-db: http://{{public-ip}}:8004
url-int-session-db-events: ws://{{public-ip}}:8005
url-ext-session-db-events: ws://{{public-ip}}:8005
url-int-scheduler: ws://{{public-ip}}:8006
url-int-file-broker: http://{{public-ip}}:8007
url-ext-file-broker: http://{{public-ip}}:8007
url-int-toolbox: http://{{public-ip}}:8008
url-ext-toolbox: http://{{public-ip}}:8008
url-int-session-worker: http://{{public-ip}}:8009
url-ext-session-worker: http://{{public-ip}}:8009
url-int-type-service: http://{{public-ip}}:8010
url-ext-type-service: http://{{public-ip}}:8010
url-int-file-storage: http://{{public-ip}}:8016

url-admin-ext-web-server: http://{{admin-ip}}:8100
url-admin-ext-auth: http://{{admin-ip}}:8102
url-admin-ext-service-locator: http://{{admin-ip}}:8103
url-admin-ext-session-db: http://{{admin-ip}}:8104
url-admin-ext-scheduler: http://{{admin-ip}}:8106
url-admin-ext-file-broker: http://{{admin-ip}}:8107
url-admin-ext-toolbox: http://{{admin-ip}}:8108
url-admin-ext-session-worker: http://{{admin-ip}}:8109
url-admin-ext-type-service: http://{{admin-ip}}:8110
url-admin-ext-comp: http://{{admin-ip}}:8111
url-admin-ext-backup: http://{{admin-ip}}:8115
url-admin-ext-job-history: http://{{admin-ip}}:8114
# this is really url-admin-int and accessed only through file-broker, but we don't yet hanle it differently in deployment scripts
url-admin-ext-file-storage: http://{{admin-ip}}:8116

# Address for the server to bind

url-bind-web-server: http://{{bind-ip}}:8000
url-bind-auth: http://{{bind-ip}}:8002
url-bind-service-locator: http://{{bind-ip}}:8003
url-bind-session-db: http://{{bind-ip}}:8004
url-bind-session-db-events: ws://{{bind-ip}}:8005
url-bind-scheduler: ws://{{bind-ip}}:8006
url-bind-file-broker: http://{{bind-ip}}:8007
url-bind-toolbox: http://{{bind-ip}}:8008
url-bind-session-worker: http://{{bind-ip}}:8009
url-bind-type-service: http://{{bind-ip}}:8010
url-bind-sso: ajp://127.0.0.1:8012
url-bind-job-history: http://{{bind-ip}}:8014
url-bind-file-storage: http://{{bind-ip}}:8016

url-admin-bind-web-server: http://{{admin-bind-ip}}:8100
url-admin-bind-auth: http://{{admin-bind-ip}}:8102
url-admin-bind-service-locator: http://{{admin-bind-ip}}:8103
url-admin-bind-session-db: http://{{admin-bind-ip}}:8104
url-admin-bind-scheduler: http://{{admin-bind-ip}}:8106
url-admin-bind-file-broker: http://{{admin-bind-ip}}:8107
url-admin-bind-toolbox: http://{{admin-bind-ip}}:8108
url-admin-bind-session-worker: http://{{admin-bind-ip}}:8109
url-admin-bind-type-service: http://{{admin-bind-ip}}:8110
url-admin-bind-comp: http://{{admin-bind-ip}}:8111
url-admin-bind-job-history: http://{{admin-bind-ip}}:8114
url-admin-bind-backup: http://{{admin-bind-ip}}:8115
url-admin-bind-file-storage: http://{{bind-ip}}:8116

# use external (public) addresses when connecting to other services 
use-external-addresses: false

# DB config defaults. Can be changed with these config keys for all the databases or overridden with <key>-<role> for individual roles 

db-show-sql: false
db-c3p0-min-size: ""
db-c3p0-max-size: ""
db-dialect: org.hibernate.dialect.PostgreSQLDialect
db-driver: org.postgresql.Driver
db-user: user
# This is just a placeholder, because it wouldn't make sense to try to restore all the databaes from the same file. Set this for individual role 
# according to instructions above.
db-restore-key: ""
db-export-schema: false
# fallback to in-memory db if connection to the configured db fails, disable in production
db-fallback: true


# db backups

backup-s3-endpoint: object.pouta.csc.fi
backup-s3-region: regionOne
backup-s3-access-key: ""
backup-s3-secret-key: ""
backup-s3-signer-override: S3SignerType
backup-bucket: ""
backup-time: 01:10

# hours, append a dash and role tune services one by one
backup-interval: 24
backup-daily-count: 90
backup-monthly-count: 24

# encrypt backups with the public key of the recipient (key must be imported in gpg)
backup-gpg-public-key: ""
backup-gpg-program: gpg2
# use symmetric encryption for the backups
backup-gpg-passphrase: ""

# JWS keys

# jws signing key, can be generated with the following command (https://connect2id.com/products/nimbus-jose-jwt/openssl-key-generation):
# openssl ecparam -genkey -name secp521r1 -noout
# If not configured, a new key will be generated on every restart, which will invalidate all old tokens.
jws-private-key-auth: ""
jws-private-key-session-db: ""
# jws signing algorithm
jws-algorithm: ES512

# auth

auth-monitoring-password: monitoring
auth-jaas-prefix: jaas

db-url-auth: jdbc:postgresql://localhost:5432/auth_db
db-pass-auth: ""

# path to JAAS config file, set to empty to use the default (which authenticates against the file security/users)
auth-jaas-conf-path: ""

# auth OpenID Connect
# register multiple oidc providers by inventing an name for each provider and appending 
# a dash and the name to each config (e.g. "-google") 

# server which hosts the discovery document in path /.well-known/openid-configuration, e.g. https://accounts.google.com
auth-oidc-issuer: ""
# client_id which you get from to oidc provider when you register your application
auth-oidc-client-id: ""
# Chipster callback path
auth-oidc-redirect-path: /oidc/callback
# "id_token" for implicit flow, "code" for authorization code flow
auth-oidc-response-type: id_token
# url or client path to the logo to show on the login page 
auth-oidc-logo: ""
auth-oidc-logo-width: ""
# login button text, if logo is not set
auth-oidc-text: "Login"
# description text
auth-oidc-description: ""
# order of the logos on the login page, ascending
auth-oidc-priority: 1
# which OIDC scopes to request
auth-oidc-scope: "openid profile email"
# store the email only if the claim "verified_email" is true
auth-oidc-verified-email-only: true
# claim name for the organization
auth-oidc-claim-organization: ""
# claim name for the user ID
auth-oidc-claim-user-id: "sub"
# append this extra parameter the the authorization URL, in format KEY=VALUE
auth-oidc-parameter: ""
# prefix for the userId, set different for each authentication provider the prevent clashes
auth-oidc-user-id-prefix: "oidc"
# appId of for this oidc config. Allow multiple apps use the same backend, but still have different oidc configs 
auth-oidc-app-id: "chipster"
# print more information about failed login attempts
auth-oidc-debug: false

# Required claims. Empty lines in between to make it readable despite the long lines. 
# accept authentication only if the token contains this claim key. Next authentication method is tried if this claim is not found
auth-oidc-required-claim-key: ""

# accept authentication only if the token contains the claim defined in auth-oidc-require-claim-key and its value matches the value given here.
auth-oidc-required-claim-value: ""

# how to compare claim values, like auth-oidc-require-userinfo-claim-value-comparison  
auth-oidc-required-claim-value-comparison: "string"

# accept authentication only if the userinfo response contains this claim key. Querying the userinfo endpoint is only possible with access token, i.e. when to response type is "code", or "id_token token". Authentication fails if this claim is not found.
auth-oidc-required-userinfo-claim-key: ""

# accept authentication only if the userinfo response contains the claim defined in auth-oidc-require-userinfo-claim-key and its value matches the value given here. Authentication fails if the value doesn't match.
auth-oidc-required-userinfo-claim-value: ""

# how to compare claim values. Set to "string" to require an exact string match. When this is set to "jsonArrayAll" or to "jsonArrayAny" the configured auth-oidc-require-userinfo-claim-value and the returned claim value is expected to be a json arrays of strings. Respectively, the claim value must contain all or at least one of the configured values.  
auth-oidc-required-userinfo-claim-value-comparison: "string"

# show this error message to the user when the required userinfo claim is not found
auth-oidc-required-userinfo-claim-error: "Chipster login is not allowed for this account"


# throttle password request for one username after too many requests during this time, seconds 
auth-password-throttle-period: 120

# throttle password request for one username after this many tries 
auth-password-throttle-request-count: 20

# user server throttle settings for these accounts, separated by space. If any real account is put here, it must have a proper password
auth-server-password-throttle-list: "unitTestUser1 unitTestUser2 monitoring"

# throttle server password request for one username after too many requests during this time, seconds
auth-server-password-throttle-period: 60

# throttle server password request for one username after this many tries 
auth-server-password-throttle-request-count: 100

 
# comp

# max number of jobs run simultaneously
comp-max-jobs: 5
# time after which a scheduled job is removed if there is no response from the scheduler
comp-schedule-timeout: 10
# delay before sending the job offer message, multiplied by number of running and scheduled jobs, milliseconds
comp-offer-delay-running-slots: 100
# fixed delay before sending the job offer message for specific job size, milliseconds
# append a dash and slot count to configure a delay for different job sizes 
comp-offer-delay-requested-slots: 0
# should job specific temporary directory be sweeped after job execution
comp-sweep-work-dir: true
# schedule timeout check interval, milliseconds
comp-timeout-check-interval: 1000
# how of to send a job heartbeat messages, milliseconds
comp-heartbeat-interval: 10000
# how of to send a comp available message, milliseconds
comp-status-interval: 30000
# name of the module to enable or disable
comp-module-filter-name: kielipankki
# 'exclude' disables the specified module and enables all other modules, 'include' enables the specified module and disables all other modules
comp-module-filter-mode: exclude 
# how often to monitor job resource usage or -1 to disable it, milliseconds
comp-resource-monitoring-interval: 10000
# timeout after which a job is killed, seconds
comp-job-timeout: 604800 # a week
# max number or threads that single job should use
comp-job-threads-max: 4
# max memory that single job should use, megabytes
comp-job-memory-max: 8192
comp-chipster-root-dir: "../"

# scheduler

# max time for comps to decide if it can run the job, seconds
scheduler-wait-timeout: 1
# max time for new job to wait for available comp, seconds
scheduler-wait-runnable-timeout: 604800 # a week
# how long to wait for job heartbeats before giving up, seconds
scheduler-heartbeat-lost-timeout: 30
# how often to check job timeouts, seconds
scheduler-job-timer-interval: 1
# max number of scheduled and running job slots per user
scheduler-max-scheduled-and-running-slots-per-user: 10
# how many job (slots) can be waiting for the free running slots (per user limit)
scheduler-max-new-slots-per-user: 1000
# get running jobs from the database in startup
scheduler-get-jobs-from-db: true
# image repository, prefix for all image names
scheduler-bash-image-repository: ""
# number of threads for BashJobScheduler
scheduler-bash-threads: 4
# max number of slots to run simultaneously in BashJobScheduler
scheduler-bash-max-slots: 5
# max valid time of the session tokens for the SingleShotComp, days
scheduler-bash-token-valid-time: 14
# enable BashJobScheduler
scheduler-bash-enabled: true

# load default bash-job-scheduler scripts from the jar package. Change to "bash-job-scheduler/k3s" if running in K3s
scheduler-bash-script-dir-in-jar: "bash-job-scheduler/process"

# use a custom bash-job-scheduler script instead
# see yaml multiline string formats if the script is longer than one line
# for example:
# scheduler-bash-run-script: |
#   echo "running..."
# 
scheduler-bash-run-script: ""
scheduler-bash-cancel-script: ""
scheduler-bash-finished-script: ""
scheduler-bash-heartbeat-script: ""
scheduler-bash-log-script: ""

# use a custom bash-job-scheduler objects
# use yaml multiline string format
# the default can be found from src/main/resources/bash-job-scheduler/*/ files pod.yaml and pvc.yaml
scheduler-bash-pod: ""
scheduler-bash-pvc: ""

scheduler-bash-storage-class: ""
  
scheduler-bash-max-slots: "100"
      
# how often to check if BashJobScheduler jobs are alive
scheduler-bash-job-timer-interval: 10

scheduler-bash-heartbeat-lost-timeout: 30

# session-db 
    
# allow sharing to everyone only for one username, empty allows for everybody
session-db-restrict-sharing-to-everyone-chipster: jaas/example_session_owner
db-url-session-db: jdbc:postgresql://localhost:5432/session_db_db
db-pass-session-db: ""

session-db-max-share-count: 100

#job-history-db
db-url-job-history: jdbc:postgresql://localhost:5432/job_history_db
db-pass-job-history: ""

# web-server

web-server-web-root-path: web-root


# toolbox

toolbox-tools-bin-path: /opt/chipster/tools

# default values for runtimes
toolbox-runtime-job-factory: fi.csc.chipster.comp.r.RJobFactory
toolbox-runtime-parameters: "--vanilla --quiet"
toolbox-runtime-image: comp-16.04
toolbox-runtime-tools-bin-volume: tools-bin-chipster-3.5.1
toolbox-runtime-tools-bin-path: /opt/chipster/tools

# add other runtimes by appending 
# a dash and the runtime name to each config (e.g. "-R-4.1.1") 
toolbox-runtime-command-R-4.1.1: /opt/chipster/tools/R-4.1.1/bin/R
toolbox-runtime-image-R-4.1.1: comp-20.04-r-deps

toolbox-runtime-command-R-4.1.1-statistics: /opt/chipster/tools/R-4.1.1-statistics/bin/R
toolbox-runtime-image-R-4.1.1-statistics: comp-20.04-r-deps

toolbox-runtime-command-R-4.1.0-single-cell: /opt/chipster/tools/R-4.1.0-single-cell/bin/R
toolbox-runtime-image-R-4.1.0-single-cell: comp-20.04-r-deps

toolbox-runtime-command-R-3.6.1-single-cell: /opt/chipster/tools/R-3.6.1-single-cell/bin/R

toolbox-runtime-command-R-3.6.1-phyloseq: /opt/chipster/tools/R-3.6.1-phyloseq/bin/R

toolbox-runtime-command-R-3.4.3: /opt/chipster/tools/R-3.4.3/bin/R

toolbox-runtime-command-R-3.3.2: /opt/chipster/tools/R-3.3.2/bin/R

toolbox-runtime-command-R: /opt/chipster/tools/R-3.2.3/bin/R

toolbox-runtime-job-factory-java: fi.csc.chipster.comp.java.JavaJobFactory
toolbox-runtime-command-java: ""
toolbox-runtime-parameters-java: ""
toolbox-runtime-image-java: comp-16.04

toolbox-runtime-job-factory-python: fi.csc.chipster.comp.python.PythonJobFactory
toolbox-runtime-command-python: python
toolbox-runtime-parameters-python: "-u"
toolbox-runtime-image-python: comp-16.04

toolbox-runtime-job-factory-python3: fi.csc.chipster.comp.python.PythonJobFactory
toolbox-runtime-command-python3: python3
toolbox-runtime-parameters-python3: ""
toolbox-runtime-image-python3: comp-16.04

# set default runtimes for different file types
toolbox-default-runtime-name-r: R
toolbox-default-runtime-file-extension-r: .R

toolbox-default-runtime-name-java: java
toolbox-default-runtime-file-extension-java: .java

toolbox-default-runtime-name-python: python
toolbox-default-runtime-file-extension-python: .py

# file-broker


# how long to wait for connections to complete after receiving SIGINT, seconds
file-broker-shutdown-timeout: 3600

# Find file-storages from the DNS server's SRV records. This is handy for Kubernetes
# statefulset, because this way the file-broker will find out automatically the number
# of file-storage replicas. Configure here the domain name of the replicaset's 
# (headless) service. You can check that records are populated correctly by running
# this command in some container:
# 
#   nslookup -type=SRV file-storage
# 
# Unfortunately the Java DNS seems to require the longer form of the domain name: 
# 
#   file-storage.NAMESPACE.svc.cluster.local
#
file-broker-storage-dns-domain-0: ""

# In addition to hostname from DNS we need also the protocol and port
file-broker-storage-dns-protocol: "http://"
file-broker-storage-dns-protocol-admin: "http://"
file-broker-storage-dns-port: "8016"
file-broker-storage-dns-port-admin: "8116"

# Add here the file-storage names that shouldn't be used for writing new files.
# The file-storage name is:
# 1) a string between "url-int-" and ":" when configured in the service-locator
# 2) a string before the first period ".", when found from the DNS
# Add as many configuration keys as require by appending new postfixes, e.g. 
# "-0", "-1" and so on.
file-broker-storage-read-only-0: ""

# When migrating files from file-broker to file-storage, the storage field in 
# the DB is null for all old files.
# If you can't copy all the files from the old file-broker to the new file-storage,
# you can configure a special read-only file-storage service that mounts the old 
# file-broker volume.
# Its name must start with "file-storage-". Let's call it "file-storage-migration" 
# in this example. Then you configure its address in the service-locator:
#
#   url-int-file-storage-migration: ADDRESS
#
# and configure here it to be used for reading all files that have null in the storage
# field:
#   
#   file-broker-storage-null: "file-storage-migration"
# 
# The file-storage configured here won't be used for writing new files.
file-broker-storage-null: ""


# file-storage

# how many percentages of the total space must remain empty after an upload (to allow other parallel uploads)
file-storage-preserve-space: 1.0

# when checking if there is enough space for a file and backups are enabled, multiply the file size with this number to make sure there is enough space for the backup processing
file-storage-backup-preserve-space: 3.0

# file-storage storageId. Hostname is used if this is not set. If set incorrectly, orphan removal will delete all files on this file-storage
file-storage-id: ""

# session-worker

session-worker-smtp-host: ""
session-worker-smtp-username: ""
session-worker-smtp-tls: false
session-worker-smtp-auth: false
session-worker-smtp-from: ""
session-worker-smtp-from-name: Chipster
session-worker-smtp-port: 25
session-worker-smtp-password: ""

session-worker-support-email-chipster: ""
# 1440 minutes = 24 hours
session-worker-support-throttle-period: 1440
session-worker-support-throttle-request-count: 20
session-worker-support-session-owner: jaas/support_session_owner
# days
session-worker-support-session-delete-after: 60

# shared

# when to timeout idle websocket connections, milliseconds. Set to zero to wait indefinitely.
websocket-idle-timeout: 300000

# send regular ping messages to prevent idle timeouts, 0 to disable
websocket-ping-interval: 120000

# variables

variable-public-ip: 127.0.0.1
variable-admin-ip: 127.0.0.1 
variable-bind-ip: 0.0.0.0
variable-admin-bind-ip: 0.0.0.0
